arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 1.13.2
--------------------
git hash: b'cc0524adb708b4b2ed4b23f486f19431670efc59'
--------------------
b'diff --git a/requirements.txt b/requirements.txt\nindex f7084e9..65c00c9 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -2,7 +2,7 @@ tensorflow==1.15.5\n keras==2.3.1\n scipy==1.1.0\n scikit-learn\n-opencv-python\n+opencv-python==4.5.5.62\n h5py\n matplotlib\n Pillow\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 7f98ca7..ec0b0d2 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -30,10 +30,11 @@ from six import string_types, iteritems\n \n import numpy as np\n import tensorflow as tf\n-#from math import floor\n+# from math import floor\n import cv2\n import os\n \n+\n def layer(op):\n     """Decorator for composable network layers."""\n \n@@ -58,6 +59,7 @@ def layer(op):\n \n     return layer_decorated\n \n+\n class Network(object):\n \n     def __init__(self, inputs, trainable=True):\n@@ -82,7 +84,7 @@ class Network(object):\n         session: The current TensorFlow session\n         ignore_missing: If true, serialized weights for missing layers are ignored.\n         """\n-        data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        data_dict = np.load(data_path, encoding=\'latin1\', allow_pickle=True).item()  # pylint: disable=no-member\n \n         for op_name in data_dict:\n             with tf.variable_scope(op_name, reuse=True):\n@@ -198,103 +200,109 @@ class Network(object):\n             fc = op(feed_in, weights, biases, name=name)\n             return fc\n \n-\n     """\n     Multi dimensional softmax,\n     refer to https://github.com/tensorflow/tensorflow/issues/210\n     compute softmax along the dimension of target\n     the native softmax only supports batch_size x dimension\n     """\n+\n     @layer\n     def softmax(self, target, axis, name=None):\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\n-        target_exp = tf.exp(target-max_axis)\n+        target_exp = tf.exp(target - max_axis)\n         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n         softmax = tf.div(target_exp, normalize, name)\n         return softmax\n-    \n+\n+\n class PNet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'PReLU1\')\n-             .max_pool(2, 2, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 16, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'PReLU2\')\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'PReLU3\')\n-             .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n-             .softmax(3,name=\'prob1\'))\n-\n-        (self.feed(\'PReLU3\') #pylint: disable=no-value-for-parameter\n-             .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n-        \n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'PReLU1\')\n+         .max_pool(2, 2, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 16, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'PReLU2\')\n+         .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'PReLU3\')\n+         .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n+         .softmax(3, name=\'prob1\'))\n+\n+        (self.feed(\'PReLU3\')  # pylint: disable=no-value-for-parameter\n+         .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n+\n+\n class RNet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 48, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(2, 2, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .fc(128, relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(2, relu=False, name=\'conv5-1\')\n-             .softmax(1,name=\'prob1\'))\n-\n-        (self.feed(\'prelu4\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv5-2\'))\n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'prelu1\')\n+         .max_pool(3, 3, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 48, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'prelu2\')\n+         .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n+         .conv(2, 2, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'prelu3\')\n+         .fc(128, relu=False, name=\'conv4\')\n+         .prelu(name=\'prelu4\')\n+         .fc(2, relu=False, name=\'conv5-1\')\n+         .softmax(1, name=\'prob1\'))\n+\n+        (self.feed(\'prelu4\')  # pylint: disable=no-value-for-parameter\n+         .fc(4, relu=False, name=\'conv5-2\'))\n+\n \n class ONet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .max_pool(2, 2, 2, 2, name=\'pool3\')\n-             .conv(2, 2, 128, 1, 1, padding=\'VALID\', relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(256, relu=False, name=\'conv5\')\n-             .prelu(name=\'prelu5\')\n-             .fc(2, relu=False, name=\'conv6-1\')\n-             .softmax(1, name=\'prob1\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv6-2\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(10, relu=False, name=\'conv6-3\'))\n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'prelu1\')\n+         .max_pool(3, 3, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'prelu2\')\n+         .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n+         .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'prelu3\')\n+         .max_pool(2, 2, 2, 2, name=\'pool3\')\n+         .conv(2, 2, 128, 1, 1, padding=\'VALID\', relu=False, name=\'conv4\')\n+         .prelu(name=\'prelu4\')\n+         .fc(256, relu=False, name=\'conv5\')\n+         .prelu(name=\'prelu5\')\n+         .fc(2, relu=False, name=\'conv6-1\')\n+         .softmax(1, name=\'prob1\'))\n+\n+        (self.feed(\'prelu5\')  # pylint: disable=no-value-for-parameter\n+         .fc(4, relu=False, name=\'conv6-2\'))\n+\n+        (self.feed(\'prelu5\')  # pylint: disable=no-value-for-parameter\n+         .fc(10, relu=False, name=\'conv6-3\'))\n+\n \n def create_mtcnn(sess, model_path):\n     if not model_path:\n-        model_path,_ = os.path.split(os.path.realpath(__file__))\n+        model_path, _ = os.path.split(os.path.realpath(__file__))\n \n     with tf.variable_scope(\'pnet\'):\n-        data = tf.placeholder(tf.float32, (None,None,None,3), \'input\')\n-        pnet = PNet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, None, None, 3), \'input\')\n+        pnet = PNet({\'data\': data})\n         pnet.load(os.path.join(model_path, \'det1.npy\'), sess)\n     with tf.variable_scope(\'rnet\'):\n-        data = tf.placeholder(tf.float32, (None,24,24,3), \'input\')\n-        rnet = RNet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, 24, 24, 3), \'input\')\n+        rnet = RNet({\'data\': data})\n         rnet.load(os.path.join(model_path, \'det2.npy\'), sess)\n     with tf.variable_scope(\'onet\'):\n-        data = tf.placeholder(tf.float32, (None,48,48,3), \'input\')\n-        onet = ONet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, 48, 48, 3), \'input\')\n+        onet = ONet({\'data\': data})\n         onet.load(os.path.join(model_path, \'det3.npy\'), sess)\n-        \n-    pnet_fun = lambda img : sess.run((\'pnet/conv4-2/BiasAdd:0\', \'pnet/prob1:0\'), feed_dict={\'pnet/input:0\':img})\n-    rnet_fun = lambda img : sess.run((\'rnet/conv5-2/conv5-2:0\', \'rnet/prob1:0\'), feed_dict={\'rnet/input:0\':img})\n-    onet_fun = lambda img : sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'), feed_dict={\'onet/input:0\':img})\n+\n+    pnet_fun = lambda img: sess.run((\'pnet/conv4-2/BiasAdd:0\', \'pnet/prob1:0\'), feed_dict={\'pnet/input:0\': img})\n+    rnet_fun = lambda img: sess.run((\'rnet/conv5-2/conv5-2:0\', \'rnet/prob1:0\'), feed_dict={\'rnet/input:0\': img})\n+    onet_fun = lambda img: sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'),\n+                                    feed_dict={\'onet/input:0\': img})\n     return pnet_fun, rnet_fun, onet_fun\n \n+\n def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n     """Detects faces in an image, and returns bounding boxes and points for them.\n     img: input image\n@@ -303,118 +311,118 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n     threshold: threshold=[th1, th2, th3], th1-3 are three steps\'s threshold\n     factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n     """\n-    factor_count=0\n-    total_boxes=np.empty((0,9))\n-    points=np.empty(0)\n-    h=img.shape[0]\n-    w=img.shape[1]\n-    minl=np.amin([h, w])\n-    m=12.0/minsize\n-    minl=minl*m\n+    factor_count = 0\n+    total_boxes = np.empty((0, 9))\n+    points = np.empty(0)\n+    h = img.shape[0]\n+    w = img.shape[1]\n+    minl = np.amin([h, w])\n+    m = 12.0 / minsize\n+    minl = minl * m\n     # create scale pyramid\n-    scales=[]\n-    while minl>=12:\n-        scales += [m*np.power(factor, factor_count)]\n-        minl = minl*factor\n+    scales = []\n+    while minl >= 12:\n+        scales += [m * np.power(factor, factor_count)]\n+        minl = minl * factor\n         factor_count += 1\n \n     # first stage\n     for scale in scales:\n-        hs=int(np.ceil(h*scale))\n-        ws=int(np.ceil(w*scale))\n+        hs = int(np.ceil(h * scale))\n+        ws = int(np.ceil(w * scale))\n         im_data = imresample(img, (hs, ws))\n-        im_data = (im_data-127.5)*0.0078125\n+        im_data = (im_data - 127.5) * 0.0078125\n         img_x = np.expand_dims(im_data, 0)\n-        img_y = np.transpose(img_x, (0,2,1,3))\n+        img_y = np.transpose(img_x, (0, 2, 1, 3))\n         out = pnet(img_y)\n-        out0 = np.transpose(out[0], (0,2,1,3))\n-        out1 = np.transpose(out[1], (0,2,1,3))\n-        \n-        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n-        \n+        out0 = np.transpose(out[0], (0, 2, 1, 3))\n+        out1 = np.transpose(out[1], (0, 2, 1, 3))\n+\n+        boxes, _ = generateBoundingBox(out1[0, :, :, 1].copy(), out0[0, :, :, :].copy(), scale, threshold[0])\n+\n         # inter-scale nms\n         pick = nms(boxes.copy(), 0.5, \'Union\')\n-        if boxes.size>0 and pick.size>0:\n-            boxes = boxes[pick,:]\n+        if boxes.size > 0 and pick.size > 0:\n+            boxes = boxes[pick, :]\n             total_boxes = np.append(total_boxes, boxes, axis=0)\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         pick = nms(total_boxes.copy(), 0.7, \'Union\')\n-        total_boxes = total_boxes[pick,:]\n-        regw = total_boxes[:,2]-total_boxes[:,0]\n-        regh = total_boxes[:,3]-total_boxes[:,1]\n-        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n-        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n-        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n-        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n-        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n+        total_boxes = total_boxes[pick, :]\n+        regw = total_boxes[:, 2] - total_boxes[:, 0]\n+        regh = total_boxes[:, 3] - total_boxes[:, 1]\n+        qq1 = total_boxes[:, 0] + total_boxes[:, 5] * regw\n+        qq2 = total_boxes[:, 1] + total_boxes[:, 6] * regh\n+        qq3 = total_boxes[:, 2] + total_boxes[:, 7] * regw\n+        qq4 = total_boxes[:, 3] + total_boxes[:, 8] * regh\n+        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:, 4]]))\n         total_boxes = rerec(total_boxes.copy())\n-        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n+        total_boxes[:, 0:4] = np.fix(total_boxes[:, 0:4]).astype(np.int32)\n         dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         # second stage\n-        tempimg = np.zeros((24,24,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n+        tempimg = np.zeros((24, 24, 3, numbox))\n+        for k in range(0, numbox):\n+            tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n+            tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = img[y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n+                tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n             else:\n                 return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n+        tempimg = (tempimg - 127.5) * 0.0078125\n+        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n         out = rnet(tempimg1)\n         out0 = np.transpose(out[0])\n         out1 = np.transpose(out[1])\n-        score = out1[1,:]\n-        ipass = np.where(score>threshold[1])\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-        if total_boxes.shape[0]>0:\n+        score = out1[1, :]\n+        ipass = np.where(score > threshold[1])\n+        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n+        mv = out0[:, ipass[0]]\n+        if total_boxes.shape[0] > 0:\n             pick = nms(total_boxes, 0.7, \'Union\')\n-            total_boxes = total_boxes[pick,:]\n-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n+            total_boxes = total_boxes[pick, :]\n+            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:, pick]))\n             total_boxes = rerec(total_boxes.copy())\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         # third stage\n         total_boxes = np.fix(total_boxes).astype(np.int32)\n         dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n-        tempimg = np.zeros((48,48,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n+        tempimg = np.zeros((48, 48, 3, numbox))\n+        for k in range(0, numbox):\n+            tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n+            tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = img[y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n+                tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n             else:\n                 return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n+        tempimg = (tempimg - 127.5) * 0.0078125\n+        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n         out = onet(tempimg1)\n         out0 = np.transpose(out[0])\n         out1 = np.transpose(out[1])\n         out2 = np.transpose(out[2])\n-        score = out2[1,:]\n+        score = out2[1, :]\n         points = out1\n-        ipass = np.where(score>threshold[2])\n-        points = points[:,ipass[0]]\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-\n-        w = total_boxes[:,2]-total_boxes[:,0]+1\n-        h = total_boxes[:,3]-total_boxes[:,1]+1\n-        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n-        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n-        if total_boxes.shape[0]>0:\n+        ipass = np.where(score > threshold[2])\n+        points = points[:, ipass[0]]\n+        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n+        mv = out0[:, ipass[0]]\n+\n+        w = total_boxes[:, 2] - total_boxes[:, 0] + 1\n+        h = total_boxes[:, 3] - total_boxes[:, 1] + 1\n+        points[0:5, :] = np.tile(w, (5, 1)) * points[0:5, :] + np.tile(total_boxes[:, 0], (5, 1)) - 1\n+        points[5:10, :] = np.tile(h, (5, 1)) * points[5:10, :] + np.tile(total_boxes[:, 1], (5, 1)) - 1\n+        if total_boxes.shape[0] > 0:\n             total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n             pick = nms(total_boxes.copy(), 0.7, \'Min\')\n-            total_boxes = total_boxes[pick,:]\n-            points = points[:,pick]\n-                \n+            total_boxes = total_boxes[pick, :]\n+            points = points[:, pick]\n+\n     return total_boxes, points\n \n \n@@ -643,60 +651,62 @@ def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, thre\n \n \n # function [boundingbox] = bbreg(boundingbox,reg)\n-def bbreg(boundingbox,reg):\n+def bbreg(boundingbox, reg):\n     """Calibrate bounding boxes"""\n-    if reg.shape[1]==1:\n+    if reg.shape[1] == 1:\n         reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n \n-    w = boundingbox[:,2]-boundingbox[:,0]+1\n-    h = boundingbox[:,3]-boundingbox[:,1]+1\n-    b1 = boundingbox[:,0]+reg[:,0]*w\n-    b2 = boundingbox[:,1]+reg[:,1]*h\n-    b3 = boundingbox[:,2]+reg[:,2]*w\n-    b4 = boundingbox[:,3]+reg[:,3]*h\n-    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n+    w = boundingbox[:, 2] - boundingbox[:, 0] + 1\n+    h = boundingbox[:, 3] - boundingbox[:, 1] + 1\n+    b1 = boundingbox[:, 0] + reg[:, 0] * w\n+    b2 = boundingbox[:, 1] + reg[:, 1] * h\n+    b3 = boundingbox[:, 2] + reg[:, 2] * w\n+    b4 = boundingbox[:, 3] + reg[:, 3] * h\n+    boundingbox[:, 0:4] = np.transpose(np.vstack([b1, b2, b3, b4]))\n     return boundingbox\n- \n+\n+\n def generateBoundingBox(imap, reg, scale, t):\n     """Use heatmap to generate bounding boxes"""\n-    stride=2\n-    cellsize=12\n+    stride = 2\n+    cellsize = 12\n \n     imap = np.transpose(imap)\n-    dx1 = np.transpose(reg[:,:,0])\n-    dy1 = np.transpose(reg[:,:,1])\n-    dx2 = np.transpose(reg[:,:,2])\n-    dy2 = np.transpose(reg[:,:,3])\n+    dx1 = np.transpose(reg[:, :, 0])\n+    dy1 = np.transpose(reg[:, :, 1])\n+    dx2 = np.transpose(reg[:, :, 2])\n+    dy2 = np.transpose(reg[:, :, 3])\n     y, x = np.where(imap >= t)\n-    if y.shape[0]==1:\n+    if y.shape[0] == 1:\n         dx1 = np.flipud(dx1)\n         dy1 = np.flipud(dy1)\n         dx2 = np.flipud(dx2)\n         dy2 = np.flipud(dy2)\n-    score = imap[(y,x)]\n-    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n-    if reg.size==0:\n-        reg = np.empty((0,3))\n-    bb = np.transpose(np.vstack([y,x]))\n-    q1 = np.fix((stride*bb+1)/scale)\n-    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n-    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n+    score = imap[(y, x)]\n+    reg = np.transpose(np.vstack([dx1[(y, x)], dy1[(y, x)], dx2[(y, x)], dy2[(y, x)]]))\n+    if reg.size == 0:\n+        reg = np.empty((0, 3))\n+    bb = np.transpose(np.vstack([y, x]))\n+    q1 = np.fix((stride * bb + 1) / scale)\n+    q2 = np.fix((stride * bb + cellsize - 1 + 1) / scale)\n+    boundingbox = np.hstack([q1, q2, np.expand_dims(score, 1), reg])\n     return boundingbox, reg\n- \n+\n+\n # function pick = nms(boxes,threshold,type)\n def nms(boxes, threshold, method):\n-    if boxes.size==0:\n-        return np.empty((0,3))\n-    x1 = boxes[:,0]\n-    y1 = boxes[:,1]\n-    x2 = boxes[:,2]\n-    y2 = boxes[:,3]\n-    s = boxes[:,4]\n-    area = (x2-x1+1) * (y2-y1+1)\n+    if boxes.size == 0:\n+        return np.empty((0, 3))\n+    x1 = boxes[:, 0]\n+    y1 = boxes[:, 1]\n+    x2 = boxes[:, 2]\n+    y2 = boxes[:, 3]\n+    s = boxes[:, 4]\n+    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n     I = np.argsort(s)\n     pick = np.zeros_like(s, dtype=np.int16)\n     counter = 0\n-    while I.size>0:\n+    while I.size > 0:\n         i = I[-1]\n         pick[counter] = i\n         counter += 1\n@@ -705,22 +715,23 @@ def nms(boxes, threshold, method):\n         yy1 = np.maximum(y1[i], y1[idx])\n         xx2 = np.minimum(x2[i], x2[idx])\n         yy2 = np.minimum(y2[i], y2[idx])\n-        w = np.maximum(0.0, xx2-xx1+1)\n-        h = np.maximum(0.0, yy2-yy1+1)\n+        w = np.maximum(0.0, xx2 - xx1 + 1)\n+        h = np.maximum(0.0, yy2 - yy1 + 1)\n         inter = w * h\n         if method is \'Min\':\n             o = inter / np.minimum(area[i], area[idx])\n         else:\n             o = inter / (area[i] + area[idx] - inter)\n-        I = I[np.where(o<=threshold)]\n+        I = I[np.where(o <= threshold)]\n     pick = pick[0:counter]\n     return pick\n \n+\n # function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n def pad(total_boxes, w, h):\n     """Compute the padding coordinates (pad the bounding boxes to square)"""\n-    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n-    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n+    tmpw = (total_boxes[:, 2] - total_boxes[:, 0] + 1).astype(np.int32)\n+    tmph = (total_boxes[:, 3] - total_boxes[:, 1] + 1).astype(np.int32)\n     numbox = total_boxes.shape[0]\n \n     dx = np.ones((numbox), dtype=np.int32)\n@@ -728,42 +739,44 @@ def pad(total_boxes, w, h):\n     edx = tmpw.copy().astype(np.int32)\n     edy = tmph.copy().astype(np.int32)\n \n-    x = total_boxes[:,0].copy().astype(np.int32)\n-    y = total_boxes[:,1].copy().astype(np.int32)\n-    ex = total_boxes[:,2].copy().astype(np.int32)\n-    ey = total_boxes[:,3].copy().astype(np.int32)\n+    x = total_boxes[:, 0].copy().astype(np.int32)\n+    y = total_boxes[:, 1].copy().astype(np.int32)\n+    ex = total_boxes[:, 2].copy().astype(np.int32)\n+    ey = total_boxes[:, 3].copy().astype(np.int32)\n \n-    tmp = np.where(ex>w)\n-    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n+    tmp = np.where(ex > w)\n+    edx.flat[tmp] = np.expand_dims(-ex[tmp] + w + tmpw[tmp], 1)\n     ex[tmp] = w\n-    \n-    tmp = np.where(ey>h)\n-    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n+\n+    tmp = np.where(ey > h)\n+    edy.flat[tmp] = np.expand_dims(-ey[tmp] + h + tmph[tmp], 1)\n     ey[tmp] = h\n \n-    tmp = np.where(x<1)\n-    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n+    tmp = np.where(x < 1)\n+    dx.flat[tmp] = np.expand_dims(2 - x[tmp], 1)\n     x[tmp] = 1\n \n-    tmp = np.where(y<1)\n-    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n+    tmp = np.where(y < 1)\n+    dy.flat[tmp] = np.expand_dims(2 - y[tmp], 1)\n     y[tmp] = 1\n-    \n+\n     return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n \n+\n # function [bboxA] = rerec(bboxA)\n def rerec(bboxA):\n     """Convert bboxA to square."""\n-    h = bboxA[:,3]-bboxA[:,1]\n-    w = bboxA[:,2]-bboxA[:,0]\n+    h = bboxA[:, 3] - bboxA[:, 1]\n+    w = bboxA[:, 2] - bboxA[:, 0]\n     l = np.maximum(w, h)\n-    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n-    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n-    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n+    bboxA[:, 0] = bboxA[:, 0] + w * 0.5 - l * 0.5\n+    bboxA[:, 1] = bboxA[:, 1] + h * 0.5 - l * 0.5\n+    bboxA[:, 2:4] = bboxA[:, 0:2] + np.transpose(np.tile(l, (2, 1)))\n     return bboxA\n \n+\n def imresample(img, sz):\n-    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n+    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA)  # @UndefinedVariable\n     return im_data\n \n     # This method is kept for debugging purpose\n@@ -778,4 +791,3 @@ def imresample(img, sz):\n #             for a3 in range(0,3):\n #                 im_data[a1,a2,a3] = img[int(floor(a1*dy)),int(floor(a2*dx)),a3]\n #     return im_data\n-\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\nindex 7d5e735..27bceb0 100644\n--- a/src/align_dataset_mtcnn.py\n+++ b/src/align_dataset_mtcnn.py\n@@ -36,32 +36,33 @@ import align.detect_face\n import random\n from time import sleep\n \n+\n def main(args):\n     sleep(random.random())\n     output_dir = os.path.expanduser(args.output_dir)\n     if not os.path.exists(output_dir):\n         os.makedirs(output_dir)\n     # Store some git revision info in a text file in the log directory\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\n+    src_path, _ = os.path.split(os.path.realpath(__file__))\n     facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n     dataset = facenet.get_dataset(args.input_dir)\n-    \n+\n     print(\'Creating networks and loading parameters\')\n-    \n+\n     with tf.Graph().as_default():\n         gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n         sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n         with sess.as_default():\n             pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n-    minsize = 20 # minimum size of face\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n-    factor = 0.709 # scale factor\n+\n+    minsize = 20  # minimum size of face\n+    threshold = [0.6, 0.7, 0.7]  # three steps\'s threshold\n+    factor = 0.709  # scale factor\n \n     # Add a random key to the filename to allow alignment using multiple processes\n     random_key = np.random.randint(0, high=99999)\n     bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n+\n     with open(bounding_boxes_filename, "w") as text_file:\n         nrof_images_total = 0\n         nrof_successfully_aligned = 0\n@@ -76,7 +77,7 @@ def main(args):\n             for image_path in cls.image_paths:\n                 nrof_images_total += 1\n                 filename = os.path.splitext(os.path.split(image_path)[1])[0]\n-                output_filename = os.path.join(output_class_dir, filename+\'.png\')\n+                output_filename = os.path.join(output_class_dir, filename + \'.png\')\n                 print(image_path)\n                 if not os.path.exists(output_filename):\n                     try:\n@@ -85,42 +86,45 @@ def main(args):\n                         errorMessage = \'{}: {}\'.format(image_path, e)\n                         print(errorMessage)\n                     else:\n-                        if img.ndim<2:\n+                        if img.ndim < 2:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n                             continue\n                         if img.ndim == 2:\n                             img = facenet.to_rgb(img)\n-                        img = img[:,:,0:3]\n-    \n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n+                        img = img[:, :, 0:3]\n+\n+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold,\n+                                                                          factor)\n                         nrof_faces = bounding_boxes.shape[0]\n-                        if nrof_faces>0:\n-                            det = bounding_boxes[:,0:4]\n+                        if nrof_faces > 0:\n+                            det = bounding_boxes[:, 0:4]\n                             det_arr = []\n                             img_size = np.asarray(img.shape)[0:2]\n-                            if nrof_faces>1:\n+                            if nrof_faces > 1:\n                                 if args.detect_multiple_faces:\n                                     for i in range(nrof_faces):\n                                         det_arr.append(np.squeeze(det[i]))\n                                 else:\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n+                                    bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\n                                     img_center = img_size / 2\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                    det_arr.append(det[index,:])\n+                                    offsets = np.vstack([(det[:, 0] + det[:, 2]) / 2 - img_center[1],\n+                                                         (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\n+                                    offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n+                                    index = np.argmax(\n+                                        bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\n+                                    det_arr.append(det[index, :])\n                             else:\n                                 det_arr.append(np.squeeze(det))\n \n                             for i, det in enumerate(det_arr):\n                                 det = np.squeeze(det)\n                                 bb = np.zeros(4, dtype=np.int32)\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                bb[0] = np.maximum(det[0] - args.margin / 2, 0)\n+                                bb[1] = np.maximum(det[1] - args.margin / 2, 0)\n+                                bb[2] = np.minimum(det[2] + args.margin / 2, img_size[1])\n+                                bb[3] = np.minimum(det[3] + args.margin / 2, img_size[0])\n+                                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]\n                                 scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n@@ -133,27 +137,29 @@ def main(args):\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n-                            \n+\n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n+\n \n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n-    \n+\n     parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n     parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n     parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n+                        help=\'Image size (height, width) in pixels.\', default=182)\n     parser.add_argument(\'--margin\', type=int,\n-        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n-        help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n+                        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n+    parser.add_argument(\'--random_order\',\n+                        help=\'Shuffles the order of images to enable alignment using multiple processes.\',\n+                        action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n+                        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n     parser.add_argument(\'--detect_multiple_faces\', type=bool,\n                         help=\'Detect and align multiple faces per image.\', default=False)\n     return parser.parse_args(argv)\n \n+\n if __name__ == \'__main__\':\n     main(parse_arguments(sys.argv[1:]))\ndiff --git a/src/face_rec_cam.py b/src/face_rec_cam.py\nindex cfbd4f4..0cd2c87 100644\n--- a/src/face_rec_cam.py\n+++ b/src/face_rec_cam.py\n@@ -5,7 +5,6 @@ from __future__ import print_function\n import tensorflow as tf\n from imutils.video import VideoStream\n \n-\n import argparse\n import facenet\n import imutils\n@@ -61,7 +60,7 @@ def main():\n             people_detected = set()\n             person_detected = collections.Counter()\n \n-            cap  = VideoStream(src=0).start()\n+            cap = VideoStream(src=0).start()\n \n             while (True):\n                 frame = cap.read()\n@@ -83,10 +82,10 @@ def main():\n                             bb[i][1] = det[i][1]\n                             bb[i][2] = det[i][2]\n                             bb[i][3] = det[i][3]\n-                            print(bb[i][3]-bb[i][1])\n+                            print(bb[i][3] - bb[i][1])\n                             print(frame.shape[0])\n-                            print((bb[i][3]-bb[i][1])/frame.shape[0])\n-                            if (bb[i][3]-bb[i][1])/frame.shape[0]>0.25:\n+                            print((bb[i][3] - bb[i][1]) / frame.shape[0])\n+                            if (bb[i][3] - bb[i][1]) / frame.shape[0] > 0.25:\n                                 cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n                                 scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n                                                     interpolation=cv2.INTER_CUBIC)\n@@ -102,23 +101,26 @@ def main():\n                                 best_name = class_names[best_class_indices[0]]\n                                 print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n \n+                                # Ve khung mau xanh quanh khuon mat\n+                                cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\n+                                text_x = bb[i][0]\n+                                text_y = bb[i][3] + 20\n \n-\n-                                if best_class_probabilities > 0.8:\n-                                    cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\n-                                    text_x = bb[i][0]\n-                                    text_y = bb[i][3] + 20\n-\n+                                # Neu ty le nhan dang > 0.5 thi hien thi ten\n+                                if best_class_probabilities > 0.5:\n                                     name = class_names[best_class_indices[0]]\n-                                    cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n-                                                1, (255, 255, 255), thickness=1, lineType=2)\n-                                    cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\n-                                                cv2.FONT_HERSHEY_COMPLEX_SMALL,\n-                                                1, (255, 255, 255), thickness=1, lineType=2)\n-                                    person_detected[best_name] += 1\n                                 else:\n+                                    # Con neu <=0.5 thi hien thi Unknow\n                                     name = "Unknown"\n \n+                                # Viet text len tren frame\n+                                cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n+                                            1, (255, 255, 255), thickness=1, lineType=2)\n+                                cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\n+                                            cv2.FONT_HERSHEY_COMPLEX_SMALL,\n+                                            1, (255, 255, 255), thickness=1, lineType=2)\n+                                person_detected[best_name] += 1\n+\n                 except:\n                     pass\n \n@@ -130,4 +132,4 @@ def main():\n             cv2.destroyAllWindows()\n \n \n-main()\n\\ No newline at end of file\n+main()'